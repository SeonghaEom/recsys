{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train purchases \n",
      "   session_id  item_id                     date\n",
      "0           3    15085  2020-12-18 21:26:47.986\n",
      "1          13    18626  2020-03-13 19:36:15.507\n",
      "2          18    24911  2020-08-26 19:20:32.049\n",
      "3          19    12534   2020-11-02 17:16:45.92\n",
      "4          24    13226  2020-02-26 18:27:44.114 (1000000, 3) 1000000\n",
      "28143\n",
      "train sessions\n",
      "   session_id  item_id                     date\n",
      "0           3     9655  2020-12-18 21:25:00.373\n",
      "1           3     9655  2020-12-18 21:19:48.093\n",
      "2          13    15654  2020-03-13 19:35:27.136\n",
      "3          18    18316  2020-08-26 19:18:30.833\n",
      "4          18     2507  2020-08-26 19:16:31.211 (4743820, 3) 1000000\n",
      "28143\n"
     ]
    }
   ],
   "source": [
    "## load train dataset\n",
    "\n",
    "tr_pur_str = '../dataset/train_purchases.csv'\n",
    "tr_purchases = pd.read_csv(tr_pur_str)\n",
    "\n",
    "tr_ses_str = '../dataset/train_sessions.csv'\n",
    "tr_sessions = pd.read_csv(tr_ses_str)\n",
    "\n",
    "\n",
    "print(\"train purchases \")\n",
    "print(tr_purchases.head(), tr_purchases.shape, len(tr_purchases['session_id'].unique()))\n",
    "print(tr_purchases['item_id'].max())\n",
    "print(\"train sessions\")\n",
    "print(tr_sessions.head(), tr_sessions.shape, len(tr_sessions['session_id'].unique()))\n",
    "print(tr_sessions['item_id'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to DateTime and sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_sessions['date'] = pd.to_datetime(tr_sessions['date'], format='%Y-%m-%d %H:%M:%S')\n",
    "# tr_sessions = tr_sessions.sort_values(['date'], ascending=True).groupby('session_id').to_frame()\n",
    "tr_sessions = tr_sessions.groupby(['session_id']).apply(lambda x: x.sort_values(['date'], ascending=True))\n",
    "print(tr_sessions.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save sorted session\n",
    "tr_sessions.to_csv('./train_sessions_sorted.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['session_id', 'Unnamed: 1', 'session_id.1', 'item_id', 'date'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "## load sorted session\n",
    "tr_sessions = pd.read_csv('../dataset/train_sessions_sorted.csv')\n",
    "print(tr_sessions.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_sessions = tr_sessions[['session_id', 'item_id', 'date']]\n",
    "tr_sessions.sort_index()\n",
    "print(tr_sessions.head())\n",
    "\n",
    "def add_row(x):\n",
    "  sid = x.iloc[0:,:]['session_id']\n",
    "  last_row = tr_purchases.loc[tr_purchases['session_id'] == sid]\n",
    "  x.append(last_row)\n",
    "tr_sessions.groupby('session_id').apply(add_row).reset_index(drop=True)\n",
    "print(tr_sessions.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insert purchase log into train sesssions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5743820, 3)\n"
     ]
    }
   ],
   "source": [
    "concat  = pd.concat((tr_sessions, tr_purchases)).sort_values(by=['session_id', 'date'], ascending=True)\n",
    "print(concat.shape)\n",
    "print(concat.head(n=10))\n",
    "print(concat.tail(n=10))\n",
    "concat.to_csv('./concat.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23618\n",
      "28143\n"
     ]
    }
   ],
   "source": [
    "concat = pd.read_csv('./concat.csv')\n",
    "concat.columns\n",
    "print(concat['item_id'].nunique())\n",
    "print(max(concat['item_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   session_id  item_id                     date\n",
      "0           3     9655  2020-12-18 21:19:48.093\n",
      "1           3     9655  2020-12-18 21:25:00.373\n",
      "2          13    15654  2020-03-13 19:35:27.136\n",
      "3          18     4026  2020-08-26 19:15:47.232\n",
      "4          18     2507  2020-08-26 19:16:31.211\n",
      "5          18    18316  2020-08-26 19:18:30.833\n",
      "6          19    19896  2020-11-02 16:30:36.378\n",
      "7          19    27937  2020-11-02 16:30:48.207\n",
      "8          19    12804  2020-11-02 16:31:05.749\n",
      "9          19    25772  2020-11-02 16:31:18.543\n",
      "   session_id  item_id                     date\n",
      "0           3    15085  2020-12-18 21:26:47.986\n",
      "1          13    18626  2020-03-13 19:36:15.507\n",
      "2          18    24911  2020-08-26 19:20:32.049\n",
      "3          19    12534   2020-11-02 17:16:45.92\n",
      "4          24    13226  2020-02-26 18:27:44.114\n",
      "5          28    26394  2020-05-18 12:52:09.764\n",
      "6          31     8345  2021-04-20 19:46:42.594\n",
      "7          36    14532  2020-06-21 10:33:22.535\n",
      "8          42    11784  2021-03-01 15:17:04.264\n",
      "9          44     4028  2020-11-27 20:46:08.951\n",
      "         session_id  item_id                     date\n",
      "4743810     4440001    10045  2020-10-30 23:26:39.481\n",
      "4743811     4440001      305  2020-10-30 23:27:37.873\n",
      "4743812     4440001    14155  2020-10-30 23:31:56.607\n",
      "4743813     4440001    23303  2020-10-30 23:32:13.354\n",
      "4743814     4440001    26067  2020-10-30 23:33:01.195\n",
      "4743815     4440001    14303  2020-10-30 23:36:17.934\n",
      "4743816     4440001    19539  2020-10-30 23:37:09.460\n",
      "4743817     4440001    20409  2020-10-30 23:37:20.658\n",
      "4743818     4440001    27852  2020-10-30 23:39:55.186\n",
      "4743819     4440001    20449  2020-10-30 23:40:28.149\n",
      "        session_id  item_id                     date\n",
      "999990     4439964    20383  2020-03-24 08:18:38.953\n",
      "999991     4439968    24013  2020-06-11 17:39:03.143\n",
      "999992     4439973    21328  2020-10-30 13:32:50.528\n",
      "999993     4439974     8932   2020-04-25 16:48:57.62\n",
      "999994     4439982    25770  2020-05-06 14:26:22.778\n",
      "999995     4439986     2915  2021-05-13 11:56:37.464\n",
      "999996     4439990     8786  2020-08-22 14:28:22.382\n",
      "999997     4439994    21630  2020-11-27 20:10:28.961\n",
      "999998     4439999    16962  2020-11-27 11:01:41.356\n",
      "999999     4440001    16631  2020-10-30 23:46:05.218\n"
     ]
    }
   ],
   "source": [
    "print(tr_sessions.head(n=10))\n",
    "print(tr_purchases.head(n=10))\n",
    "print(tr_sessions.tail(n=10))\n",
    "print(tr_purchases.tail(n=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_sessions = tr_sessions[['session_id', 'item_id', 'date']]\n",
    "tr_sessions['date'] = pd.to_datetime(tr_sessions['date'], format='%Y-%m-%d %H:%M:%S')\n",
    "tr_sessions_gb = tr_sessions.groupby(['session_id'])\n",
    "\n",
    "from collections import defaultdict\n",
    "dic = defaultdict(list)\n",
    "for gr_name, gr in tr_sessions_gb:\n",
    "  dic['session_id'].append(gr_name)\n",
    "  dic['item_first_clicked'].append(gr.iloc[0,:]['item_id']) #categorical\n",
    "  dic['year'].append(int(gr.iloc[0,:]['date'].year)) #numerical\n",
    "  dic['month'].append(int(gr.iloc[0,:]['date'].month)) #numerical\n",
    "  dic['day'].append(int(gr.iloc[0,:]['date'].day)) #numerical\n",
    "  dic['hour'].append(int(gr.iloc[0,:]['date'].hour)) #numerical\n",
    "  dic['weekofyear'].append(int(gr.iloc[0,:]['date'].weekofyear))\n",
    "  dic['weekday'].append(int(gr.iloc[0,:]['date'].weekday())) #categorical\n",
    "  dic['num_clicks'].append(gr.shape[0]) #numerical\n",
    "  dic['duration'].append((gr.iloc[-1,:]['date'] - gr.iloc[0,:]['date']).total_seconds()//60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(dic).to_csv('./feat_extract.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load item features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate train dataset txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23691\n"
     ]
    }
   ],
   "source": [
    "id2idx = {}\n",
    "item_features = pd.read_csv('../dataset/item_features.csv')\n",
    "for i, item_id in enumerate(item_features.item_id.unique()):\n",
    "  id2idx[item_id] = i\n",
    "print(len(id2idx.keys()))\n",
    "# id2idx_df = pd.DataFrame(list(id2idx.items()),columns = ['item_id','item_idx'])\n",
    "# id2idx_df.to_csv('./id2idx.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate Train dataset txt file\n",
    "tr_purchases = pd.read_csv('../dataset/train_purchases.csv')\n",
    "sids = tr_purchases['session_id'].unique()\n",
    "\n",
    "\n",
    "with open('./train.txt', 'w') as f:\n",
    "  for sid in sids:\n",
    "    sess = tr_sessions.loc[tr_sessions['session_id'] == sid]['item_id'].tolist()\n",
    "    sess = [id2idx[i] for i in sess]\n",
    "    pur = id2idx[tr_purchases.loc[tr_purchases['session_id'] == sid]['item_id'].values[0]]\n",
    "    sess.append(pur)\n",
    "    string = \",\".join(map(str,sess)) + '\\n'\n",
    "    f.write(string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### groupby\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23496\n",
      "23496\n"
     ]
    }
   ],
   "source": [
    "sess_grouped = tr_sessions.sort_values('date')\n",
    "sess_grouped['id'] = tr_sessions.groupby(['session_id']).ngroup()\n",
    "# sess_grouped.groups\n",
    "# sess_grouped.reset_index()\n",
    "sess_grouped\n",
    "\n",
    "item_ids = tr_sessions['item_id'].unique()\n",
    "print(len(item_ids))\n",
    "item_id_dict = dict.fromkeys(item_ids)\n",
    "for i, itemid in enumerate(item_ids):\n",
    "  item_id_dict[itemid] = i\n",
    "item_id_dict\n",
    "print(len(item_id_dict.keys()))\n",
    "\n",
    "sess_grouped['item_id'] = sess_grouped['item_id'].apply(lambda x: item_id_dict[x])\n",
    "sess_grouped['item_id'].max()\n",
    "\n",
    "sess_grouped.to_csv('./sess_grouped.csv')\n",
    "sess_grouped.to_csv('./train.csv', columns=['id', 'item_id'], header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot session length of each sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "from collections import defaultdict\n",
    "dic = defaultdict(int)\n",
    "\n",
    "# tr_sessions.groupby(['session_id']).sort_values([''])\n",
    "session_id = tr_sessions['session_id'].unique()\n",
    "for sid in session_id:\n",
    "  length = len(tr_sessions.loc[tr_sessions['session_id'] == sid]['item_id'].to_list())\n",
    "  if length < 20:\n",
    "    dic[length] += 1\n",
    "  else:\n",
    "    dic['rest'] +=1\n",
    "\n",
    "y = []\n",
    "for k,v in dic.items():\n",
    "  y.append(v)\n",
    "ax.bar(dic.keys(),y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD TEST SESSION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test sessions\n",
      "   session_id  item_id                     date\n",
      "0          26    19185  2021-06-16 09:53:54.158\n",
      "1         200    17089  2021-06-25 12:23:40.811\n",
      "2         200    17089  2021-06-25 12:24:36.631\n",
      "3         200     8060  2021-06-25 12:24:41.677\n",
      "4         200     4758  2021-06-25 12:24:50.692 (229354, 3) 50000\n",
      "28137\n",
      "test sessions\n",
      "   session_id  item_id                     date\n",
      "0          61    27088  2021-06-01 08:12:39.664\n",
      "1          96    11693  2021-06-19 17:48:05.227\n",
      "2          96    18298  2021-06-19 17:49:08.589\n",
      "3          96     4738  2021-06-19 17:49:15.838\n",
      "4          96      495   2021-06-19 17:49:20.88 (226138, 3) 50000\n",
      "28137\n"
     ]
    }
   ],
   "source": [
    "## load test session\n",
    "\n",
    "te_leaderboard_sessions_str = './test_leaderboard_sessions.csv'\n",
    "te_leaderboard_sessions = pd.read_csv('./test_leaderboard_sessions.csv')\n",
    "print(\"test sessions\")\n",
    "print(te_leaderboard_sessions.head(), te_leaderboard_sessions.shape, len(te_leaderboard_sessions['session_id'].unique()))\n",
    "print(te_leaderboard_sessions['item_id'].max())\n",
    "\n",
    "te_final_sessions_str = './test_final_sessions.csv'\n",
    "te_final_sessions = pd.read_csv('./test_final_sessions.csv')\n",
    "print(\"test sessions\")\n",
    "print(te_final_sessions.head(), te_final_sessions.shape, len(te_final_sessions['session_id'].unique()))\n",
    "print(te_final_sessions['item_id'].max())\n",
    "# te_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              session_id  item_id                    date\n",
      "session_id                                               \n",
      "26         0          26    19185 2021-06-16 09:53:54.158\n",
      "200        1         200    17089 2021-06-25 12:23:40.811\n",
      "           2         200    17089 2021-06-25 12:24:36.631\n",
      "           3         200     8060 2021-06-25 12:24:41.677\n",
      "           4         200     4758 2021-06-25 12:24:50.692\n",
      "              session_id  item_id                    date\n",
      "session_id                                               \n",
      "61         0          61    27088 2021-06-01 08:12:39.664\n",
      "96         1          96    11693 2021-06-19 17:48:05.227\n",
      "           2          96    18298 2021-06-19 17:49:08.589\n",
      "           3          96     4738 2021-06-19 17:49:15.838\n",
      "           4          96      495 2021-06-19 17:49:20.880\n"
     ]
    }
   ],
   "source": [
    "te_leaderboard_sessions['date'] = pd.to_datetime(te_leaderboard_sessions['date'], format='%Y-%m-%d %H:%M:%S')\n",
    "# tr_sessions = tr_sessions.sort_values(['date'], ascending=True).groupby('session_id').to_frame()\n",
    "te_leaderboard_sessions = te_leaderboard_sessions.groupby(['session_id']).apply(lambda x: x.sort_values(['date'], ascending=True))\n",
    "print(te_leaderboard_sessions.head())\n",
    "\n",
    "te_final_sessions['date'] = pd.to_datetime(te_final_sessions['date'], format='%Y-%m-%d %H:%M:%S')\n",
    "# tr_sessions = tr_sessions.sort_values(['date'], ascending=True).groupby('session_id').to_frame()\n",
    "te_final_sessions = te_final_sessions.groupby(['session_id']).apply(lambda x: x.sort_values(['date'], ascending=True))\n",
    "print(te_final_sessions.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generate test datset txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate Test dataset txt file\n",
    "sids = te_leaderboard_sessions['session_id'].unique()\n",
    "\n",
    "with open('../datasets/dressipi/test.txt', 'w') as f:\n",
    "  for sid in sids:\n",
    "    sess = te_leaderboard_sessions.loc[te_leaderboard_sessions['session_id'] == sid]['item_id'].tolist()\n",
    "    sess.append(te_leaderboard_sessions.loc[te_leaderboard_sessions['session_id'] == sid]['item_id'].values[0])\n",
    "    string = \",\".join(map(str,sess)) + '\\n'\n",
    "    f.write(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate Test dataset txt file\n",
    "sids = te_final_sessions['session_id'].unique()\n",
    "\n",
    "with open('../datasets/dressipi/test_final.txt', 'w') as f:\n",
    "  for sid in sids:\n",
    "    sess = te_final_sessions.loc[te_final_sessions['session_id'] == sid]['item_id'].tolist()\n",
    "    # sess.append(te_final_sessions.loc[te_final_sessions['session_id'] == sid]['item_id'].values[0])\n",
    "    string = \",\".join(map(str,sess)) + '\\n'\n",
    "    f.write(string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataset statistics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def print_statistics(fn):\n",
    "  with open(fn, 'r') as f:\n",
    "    session = f.readlines()\n",
    "\n",
    "  len(session)\n",
    "  session = [s.split(',') for s in session]\n",
    "  li = list(map(len, session))\n",
    "  print(\"average length \", sum(li)/len(li))\n",
    "  print(\"maximum length\", max(li))\n",
    "\n",
    "  larger = sum(map((lambda x: x>5), li))\n",
    "  print(\"session length larger than 5: \", larger)\n",
    "  smaller = sum(map((lambda x: x<=5), li))\n",
    "  print(\"session length smaller or equal to 5: \", smaller)\n",
    "\n",
    "print_statistics('../datasets/dressipi/test.txt')\n",
    "print_statistics('../datasets/dressipi/test_final.txt')\n",
    "print_statistics('../datasets/dressipi/train.txt')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5647\n",
      "5647\n",
      "5646\n"
     ]
    }
   ],
   "source": [
    "sess_grouped = te_leaderboard_sessions\n",
    "sess_grouped['id'] = te_leaderboard_sessions.groupby(['session_id']).ngroup()\n",
    "# sess_grouped.groups\n",
    "# sess_grouped.reset_index()\n",
    "sess_grouped\n",
    "\n",
    "item_ids = te_leaderboard_sessions['item_id'].unique()\n",
    "print(len(item_ids))\n",
    "item_id_dict = dict.fromkeys(item_ids)\n",
    "for i, itemid in enumerate(item_ids):\n",
    "  item_id_dict[itemid] = i\n",
    "item_id_dict\n",
    "print(len(item_id_dict.keys()))\n",
    "\n",
    "sess_grouped['item_id'] = sess_grouped['item_id'].apply(lambda x: item_id_dict[x])\n",
    "print(sess_grouped['item_id'].max())\n",
    "\n",
    "sess_grouped.to_csv('./sess_grouped.csv')\n",
    "sess_grouped.to_csv('./test.csv', columns=['id', 'item_id'], header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4439646</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4439648</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4439675</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4439868</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4439966</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            size\n",
       "session_id      \n",
       "61             1\n",
       "96             5\n",
       "185            5\n",
       "224            2\n",
       "285            1\n",
       "...          ...\n",
       "4439646        4\n",
       "4439648        1\n",
       "4439675        1\n",
       "4439868        1\n",
       "4439966        2\n",
       "\n",
       "[50000 rows x 1 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def session_length(session_pd, path):\n",
    "  ## get length of each session\n",
    "  sess_grouped = session_pd.groupby(['session_id']).size().to_frame('size')\n",
    "  # sess_grouped['size'] = sess_grouped['session_id'].transform('size')\n",
    "  fn = path.split('/')[-1]\n",
    "  sess_grouped.to_csv('./{}_grouped.csv'.format(fn))\n",
    "  return sess_grouped\n",
    "\n",
    "tr_sess_gr = session_length(tr_sessions, tr_ses_str)\n",
    "session_length(te_leaderboard_sessions, te_leaderboard_sessions_str)\n",
    "session_length(te_final_sessions, te_final_sessions_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1     307698\n",
      "2     174775\n",
      "3     115499\n",
      "4      82306\n",
      "5      60695\n",
      "       ...  \n",
      "91         6\n",
      "96         6\n",
      "98         5\n",
      "99         5\n",
      "89         5\n",
      "Name: size, Length: 100, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## count session length\n",
    "print(tr_sess_gr['size'].value_counts())\n",
    "tr_sess_gr['size'].value_counts().to_csv('./train_session_length.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item_features\n",
      "   item_id  feature_category_id  feature_value_id\n",
      "0        2                   56               365\n",
      "1        2                   62               801\n",
      "2        2                   68               351\n",
      "3        2                   33               802\n",
      "4        2                   72                75 (471751, 3)\n",
      "23691 73 890\n"
     ]
    }
   ],
   "source": [
    "it_feat_str = './item_features.csv'\n",
    "item_features = pd.read_csv(it_feat_str)\n",
    "\n",
    "print(\"item_features\")\n",
    "print(item_features.head(), item_features.shape)\n",
    "print(len(item_features['item_id'].unique()), len(item_features['feature_category_id'].unique()), len(item_features['feature_value_id'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate items\n",
      "   item_id\n",
      "0        4\n",
      "1        8\n",
      "2        9\n",
      "3       19\n",
      "4       20 (4990, 1)\n"
     ]
    }
   ],
   "source": [
    "cand_it_str = './candidate_items.csv'\n",
    "candidate_items = pd.read_csv(cand_it_str)\n",
    "\n",
    "print(\"candidate items\")\n",
    "print(candidate_items.head(), candidate_items.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f6795b7e335e45d28e9efdbdc5fd8d01cb8d10405706726ed248b9c8edb4faec"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('serec')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
