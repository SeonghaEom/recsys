{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/seongha/anaconda3/envs/serec/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch as t\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "FA_10_feat = t.FloatTensor(np.load('../processed/FA_10_feat.npy'))\n",
    "normed_matrix = t.FloatTensor(np.load('./norm_A.npy'))\n",
    "in_feat = 10\n",
    "out_feat = 23691\n",
    "device = t.device('cuda' if t.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=10, out_features=23691, bias=True)\n",
      "  (dropout1): Dropout2d(p=0.25, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# In[2]:\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, in_feat, out_feat):\n",
    "      super(Net, self).__init__()\n",
    "\n",
    "      self.fc1 = nn.Linear(in_feat, out_feat)\n",
    "      self.dropout1 = nn.Dropout2d(0.25)\n",
    "      # self.fc2 = nn.Linear(523, 19021)\n",
    "\n",
    "    def forward(self, x):\n",
    "      x = self.fc1(x)\n",
    "      x = t.relu(x)\n",
    "\n",
    "      # Apply softmax to x\n",
    "      output = F.softmax(x, dim=1)\n",
    "      return output\n",
    "\n",
    "\n",
    "my_nn = Net(in_feat, out_feat).to(device)\n",
    "print(my_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_items = 23691\n",
    "from tqdm import tqdm\n",
    "from scipy import sparse\n",
    "from torch.utils.data import Dataset, Data, TemporalData\n",
    "from torch_sparse import SparseTensor\n",
    "import torch_geometric.transforms as T\n",
    "AX = t.matmul(normed_matrix, FA_10_feat) ## 23691, 128\n",
    "class Dataset(Dataset):\n",
    "  def __init__(self, file, root_dir=None):\n",
    "    with open(file, 'r') as f:\n",
    "      self.sessions = f.readlines()[:]\n",
    "    self.root_dir = root_dir\n",
    "    self.adj = None\n",
    "\n",
    "    self.edge_index = [[],[]]\n",
    "    self.y = []\n",
    "    for line in self.sessions:\n",
    "      items = list(map(int, line.split(\",\")))\n",
    "      self.edge_index[0].extend(items[:-1])\n",
    "      self.edge_index[1].extend(items[1:])\n",
    "      self.y.append(items[-1])\n",
    "    \n",
    "    self.edge_index = t.LongTensor(np.array(self.edge_index, dtype=np.float64))\n",
    "    self.y = t.LongTensor(np.array(self.y, dtype=np.float64))\n",
    "    print(self.edge_index)\n",
    "    self.adj = SparseTensor(row=self.edge_index[0], col=self.edge_index[1], sparse_sizes=(num_items, num_items))\n",
    "    print(self.adj, self.y.shape)\n",
    "\n",
    "    events = TemporalData(src=t.Tensor(self.edge_index[0],\n",
    "      dst=t.Tensor(self.edge_index[1]),\n",
    "    ))\n",
    "\n",
    "    self.x = FA_10_feat\n",
    "    self.num_features = self.x.shape[1]\n",
    "    self.num_classes = 23691\n",
    "    \n",
    "def __getitem__(self, idx):\n",
    "  session = self.edge_index[idx]\n",
    "  label = self.y\n",
    "  return session, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating dataset,,\n",
      "tensor([[ 8122,  8122, 13198,  ..., 17238, 23434, 17271],\n",
      "        [ 8122, 12704, 15717,  ..., 23434, 17271, 14028]])\n",
      "SparseTensor(row=tensor([    0,     1,     1,  ..., 23690, 23690, 23690]),\n",
      "             col=tensor([14648,     1,     1,  ..., 23690, 23690, 23690]),\n",
      "             size=(23691, 23691), nnz=4743820, density=0.85%) torch.Size([1000000])\n",
      "now loader..\n"
     ]
    }
   ],
   "source": [
    "print(\"generating dataset,,\")\n",
    "trainset = Dataset('./train.txt', )\n",
    "from torch.utils.data import DataLoader\n",
    "print(\"now loader..\")\n",
    "trainloader = DataLoader(trainset, batch_size=16, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(a, num_classes=23691):\n",
    "  return np.squeeze(np.eye(num_classes)[a.reshape(-1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([23691, 23691])\n",
      "torch.Size([100, 23691])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected input batch_size (23691) to match target batch_size (100).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/seongha/GRU4REC-pytorch/notebooks/trainsessions.ipynb Cell 6'\u001b[0m in \u001b[0;36m<cell line: 36>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B143.248.157.143/home/seongha/GRU4REC-pytorch/notebooks/trainsessions.ipynb#ch0000012vscode-remote?line=33'>34</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mfloat\u001b[39m(loss)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B143.248.157.143/home/seongha/GRU4REC-pytorch/notebooks/trainsessions.ipynb#ch0000012vscode-remote?line=35'>36</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39m201\u001b[39m):\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B143.248.157.143/home/seongha/GRU4REC-pytorch/notebooks/trainsessions.ipynb#ch0000012vscode-remote?line=36'>37</a>\u001b[0m     loss \u001b[39m=\u001b[39m train(trainset)\n",
      "\u001b[1;32m/home/seongha/GRU4REC-pytorch/notebooks/trainsessions.ipynb Cell 6'\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B143.248.157.143/home/seongha/GRU4REC-pytorch/notebooks/trainsessions.ipynb#ch0000012vscode-remote?line=28'>29</a>\u001b[0m oh \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mone_hot(data\u001b[39m.\u001b[39my, num_classes\u001b[39m=\u001b[39m\u001b[39m23691\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B143.248.157.143/home/seongha/GRU4REC-pytorch/notebooks/trainsessions.ipynb#ch0000012vscode-remote?line=29'>30</a>\u001b[0m \u001b[39mprint\u001b[39m(oh\u001b[39m.\u001b[39mshape)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B143.248.157.143/home/seongha/GRU4REC-pytorch/notebooks/trainsessions.ipynb#ch0000012vscode-remote?line=30'>31</a>\u001b[0m loss \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39;49mnll_loss(out, oh)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B143.248.157.143/home/seongha/GRU4REC-pytorch/notebooks/trainsessions.ipynb#ch0000012vscode-remote?line=31'>32</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B143.248.157.143/home/seongha/GRU4REC-pytorch/notebooks/trainsessions.ipynb#ch0000012vscode-remote?line=32'>33</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/anaconda3/envs/serec/lib/python3.8/site-packages/torch/nn/functional.py:2532\u001b[0m, in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   <a href='file:///home/seongha/anaconda3/envs/serec/lib/python3.8/site-packages/torch/nn/functional.py?line=2529'>2530</a>\u001b[0m \u001b[39mif\u001b[39;00m size_average \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m reduce \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   <a href='file:///home/seongha/anaconda3/envs/serec/lib/python3.8/site-packages/torch/nn/functional.py?line=2530'>2531</a>\u001b[0m     reduction \u001b[39m=\u001b[39m _Reduction\u001b[39m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> <a href='file:///home/seongha/anaconda3/envs/serec/lib/python3.8/site-packages/torch/nn/functional.py?line=2531'>2532</a>\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49mnll_loss_nd(\u001b[39minput\u001b[39;49m, target, weight, _Reduction\u001b[39m.\u001b[39;49mget_enum(reduction), ignore_index)\n",
      "\u001b[0;31mValueError\u001b[0m: Expected input batch_size (23691) to match target batch_size (100)."
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import MessagePassing\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch_geometric.nn import GCNConv\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(trainset.num_features, 16, cached=True)\n",
    "        self.conv2 = GCNConv(16, trainset.num_classes, cached=True)\n",
    "\n",
    "    def forward(self, x, adj_t):\n",
    "        x = self.conv1(x, adj_t)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, adj_t)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "model = GNN()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "# loss_func = nn.MSELoss()\n",
    "\n",
    "def train(data):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.adj.t())\n",
    "    print(out.shape)\n",
    "    oh = F.one_hot(data.y, num_classes=23691)\n",
    "    print(oh.shape)\n",
    "    loss = F.nll_loss(out, oh)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return float(loss)\n",
    "\n",
    "for epoch in range(1, 201):\n",
    "    loss = train(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = t.optim.SGD(linear_model.parameters(), lr = 0.01, weight_decay = 0)\n",
    "loss_func = nn.MSELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "  my_nn.train()\n",
    "  for i, (sess, label) in tqdm(enumerate(trainloader)):\n",
    "    print(\"epoch \", i)\n",
    "    # print(sess.shape, label.shape)\n",
    "    # sess = t.matmul(sess.to_dense(), AX).to_sparse() ## 23691 23691 23691 * 128 -> 23691 * 128\n",
    "    # print(sess)\n",
    "    sess = sess.to(device)\n",
    "    logit = my_nn(sess)\n",
    "    # label = t.tensor(label, dtype=t.int64).to(device)\n",
    "    label = t.from_numpy(one_hot(np.array(label)))\n",
    "    label = (label).to(device)\n",
    "    # logit = logit.mean(dim=0)\n",
    "    # print(logit.shape, label.shape)\n",
    "\n",
    "    loss = loss_func(logit.to(t.float64), label.to(t.float64))\n",
    "    # print(loss)\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "\n",
    "def validate():\n",
    "  my_nn.eval()\n",
    "  for i, (sess, label) in tqdm(enumerate(valloader)):\n",
    "    print(\"epoch \", i)\n",
    "    # print(sess.shape, label.shape)\n",
    "    # sess = t.matmul(sess.to_dense(), AX).to_sparse() ## 23691 23691 23691 * 128 -> 23691 * 128\n",
    "    # print(sess)\n",
    "    sess = sess.to(device)\n",
    "    logit = my_nn(sess)\n",
    "    # label = t.tensor(label, dtype=t.int64).to(device)\n",
    "    label_oh = t.from_numpy(one_hot(np.array(label)))\n",
    "    label_oh = (label_oh).to(device)\n",
    "    # logit = logit.mean(dim=0)\n",
    "    # print(logit.shape, label.shape)\n",
    "    top100, indices = logit.topk(k=100)\n",
    "    print(indices.shape)\n",
    "    print(get_mrr(indices.cpu(), label))\n",
    "    # print(top100, indices)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mrr(indices, targets): #Mean Receiprocal Rank --> Average of rank of next item in the session.\n",
    "    \"\"\"\n",
    "    Calculates the MRR score for the given predictions and targets\n",
    "    Args:\n",
    "        indices (Bxk): torch.LongTensor. top-k indices predicted by the model.\n",
    "        targets (B): torch.LongTensor. actual target indices.\n",
    "    Returns:\n",
    "        mrr (float): the mrr score\n",
    "    \"\"\"\n",
    "    tmp = targets.view(-1, 1)\n",
    "    targets = tmp.expand_as(indices)\n",
    "    # print(indices[:10,:], targets[:10,:])\n",
    "    hits = (targets == indices).nonzero()\n",
    "    # print(\"hits \", hits)\n",
    "    ranks = hits[:, -1] + 1\n",
    "    ranks = ranks.float()\n",
    "    # print(\"ranks \", ranks)\n",
    "    rranks = t.reciprocal(ranks)\n",
    "    mrr = t.sum(rranks).data / targets.size(0)\n",
    "    return mrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00, 19.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  0\n",
      "torch.Size([16, 100])\n",
      "tensor(0.)\n",
      "epoch  1\n",
      "torch.Size([16, 100])\n",
      "tensor(0.)\n",
      "epoch  2\n",
      "torch.Size([16, 100])\n",
      "tensor(0.)\n",
      "epoch  3\n",
      "torch.Size([16, 100])\n",
      "tensor(0.)\n",
      "epoch  4\n",
      "torch.Size([16, 100])\n",
      "tensor(0.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:00, 25.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  5\n",
      "torch.Size([16, 100])\n",
      "tensor(0.)\n",
      "epoch  6\n",
      "torch.Size([16, 100])\n",
      "tensor(0.)\n",
      "epoch  7\n",
      "torch.Size([16, 100])\n",
      "tensor(0.)\n",
      "epoch  8\n",
      "torch.Size([16, 100])\n",
      "tensor(0.)\n",
      "epoch  9\n",
      "torch.Size([16, 100])\n",
      "tensor(0.)\n",
      "epoch  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16it [00:00, 27.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 100])\n",
      "tensor(0.)\n",
      "epoch  11\n",
      "torch.Size([16, 100])\n",
      "tensor(0.)\n",
      "epoch  12\n",
      "torch.Size([16, 100])\n",
      "tensor(0.)\n",
      "epoch  13\n",
      "torch.Size([16, 100])\n",
      "tensor(0.0018)\n",
      "epoch  14\n",
      "torch.Size([16, 100])\n",
      "tensor(0.)\n",
      "epoch  15\n",
      "torch.Size([16, 100])\n",
      "tensor(0.)\n",
      "epoch  16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22it [00:00, 27.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 100])\n",
      "tensor(0.)\n",
      "epoch  17\n",
      "torch.Size([16, 100])\n",
      "tensor(0.)\n",
      "epoch  18\n",
      "torch.Size([16, 100])\n",
      "tensor(0.)\n",
      "epoch  19\n",
      "torch.Size([16, 100])\n",
      "tensor(0.)\n",
      "epoch  20\n",
      "torch.Size([16, 100])\n",
      "tensor(0.)\n",
      "epoch  21\n",
      "torch.Size([16, 100])\n",
      "tensor(0.)\n",
      "epoch  22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25it [00:01, 21.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 100])\n",
      "tensor(0.0017)\n",
      "epoch  23\n",
      "torch.Size([16, 100])\n",
      "tensor(0.0008)\n",
      "epoch  24\n",
      "torch.Size([16, 100])\n",
      "tensor(0.)\n",
      "epoch  25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28it [00:01, 21.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 100])\n",
      "tensor(0.)\n",
      "epoch  26\n",
      "torch.Size([16, 100])\n",
      "tensor(0.0019)\n",
      "epoch  27\n",
      "torch.Size([16, 100])\n",
      "tensor(0.)\n",
      "epoch  28\n",
      "torch.Size([16, 100])\n",
      "tensor(0.)\n",
      "epoch  29\n",
      "torch.Size([16, 100])\n",
      "tensor(0.)\n",
      "epoch  30\n",
      "torch.Size([16, 100])\n",
      "tensor(0.)\n",
      "epoch  31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "36it [00:01, 26.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 100])\n",
      "tensor(0.)\n",
      "epoch  32\n",
      "torch.Size([16, 100])\n",
      "tensor(0.)\n",
      "epoch  33\n",
      "torch.Size([16, 100])\n",
      "tensor(0.)\n",
      "epoch  34\n",
      "torch.Size([16, 100])\n",
      "tensor(0.)\n",
      "epoch  35\n",
      "torch.Size([16, 100])\n",
      "tensor(0.)\n",
      "epoch  36\n",
      "torch.Size([16, 100])\n",
      "tensor(0.0023)\n",
      "epoch  37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "43it [00:01, 27.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 100])\n",
      "tensor(0.)\n",
      "epoch  38\n",
      "torch.Size([16, 100])\n",
      "tensor(0.)\n",
      "epoch  39\n",
      "torch.Size([16, 100])\n",
      "tensor(0.)\n",
      "epoch  40\n",
      "torch.Size([16, 100])\n",
      "tensor(0.)\n",
      "epoch  41\n",
      "torch.Size([16, 100])\n",
      "tensor(0.)\n",
      "epoch  42\n",
      "torch.Size([16, 100])\n",
      "tensor(0.)\n",
      "epoch  43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "46it [00:01, 26.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 100])\n",
      "tensor(0.)\n",
      "epoch  44\n",
      "torch.Size([16, 100])\n",
      "tensor(0.)\n",
      "epoch  45\n",
      "torch.Size([16, 100])\n",
      "tensor(0.)\n",
      "epoch  46\n",
      "torch.Size([16, 100])\n",
      "tensor(0.)\n",
      "epoch  47\n",
      "torch.Size([16, 100])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "52it [00:02, 24.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0012)\n",
      "epoch  48\n",
      "torch.Size([16, 100])\n",
      "tensor(0.)\n",
      "epoch  49\n",
      "torch.Size([16, 100])\n",
      "tensor(0.)\n",
      "epoch  50\n",
      "torch.Size([16, 100])\n",
      "tensor(0.)\n",
      "epoch  51\n",
      "torch.Size([16, 100])\n",
      "tensor(0.)\n",
      "epoch  52\n",
      "torch.Size([16, 100])\n",
      "tensor(0.)\n",
      "epoch  53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "58it [00:02, 26.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 100])\n",
      "tensor(0.)\n",
      "epoch  54\n",
      "torch.Size([16, 100])\n",
      "tensor(0.)\n",
      "epoch  55\n",
      "torch.Size([16, 100])\n",
      "tensor(0.)\n",
      "epoch  56\n",
      "torch.Size([16, 100])\n",
      "tensor(0.)\n",
      "epoch  57\n",
      "torch.Size([16, 100])\n",
      "tensor(0.)\n",
      "epoch  58\n",
      "torch.Size([16, 100])\n",
      "tensor(0.)\n",
      "epoch  59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "63it [00:02, 25.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 100])\n",
      "tensor(0.)\n",
      "epoch  60\n",
      "torch.Size([16, 100])\n",
      "tensor(0.)\n",
      "epoch  61\n",
      "torch.Size([16, 100])\n",
      "tensor(0.)\n",
      "epoch  62\n",
      "torch.Size([8, 100])\n",
      "tensor(0.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f6795b7e335e45d28e9efdbdc5fd8d01cb8d10405706726ed248b9c8edb4faec"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('serec')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
